{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arseno Feri Alzahabi | arse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIc-fQk96x90"
   },
   "source": [
    "# Generative AI for Financial Chatbots Development\n",
    "\n",
    "Congratulations on making it this far in this self-paced Generative AI lesson series! Before you attempt this challenge, you should complete the workbook to have a baseline understanding of the materials presented in the challenge:\n",
    "\n",
    "- [Generative AI Series 1: Generative AI for Finance](https://docs.sectors.app/recipes/generative-ai-python/01-background)\n",
    "- [Generative AI Series 2: Tool Use and Function Calling for Finance LLMs](https://docs.sectors.app/recipes/generative-ai-python/02-tool-use)\n",
    "- [Generative AI Series 3: Structured Output](https://docs.sectors.app/recipes/generative-ai-python/03-structured-output)\n",
    "- [Generative AI Series 4: Conversational Tool Use AI](https://docs.sectors.app/recipes/generative-ai-python/04-conversational)\n",
    "\n",
    "---\n",
    "\n",
    "## Generative AI Workshop\n",
    "\n",
    "The materials are specifically designed for the following workshop by Supertype, and it might be beneficial to join the workshop (\\$9, +\\$4 for certification grading, post-workshop support and API credits) for a live-instructor, hands-on experience if you're new to the topics covered.\n",
    "\n",
    "- [Generative AI for financial chatbots workshop](https://supertype.ai/financial-chatbots/)\n",
    "\n",
    "## Make a Copy for submission\n",
    "Please use File > Save a Copy in Drive to duplicate this assignment template.\n",
    "\n",
    "When you have completed the challenge, submit it to the GitHub discussion thread for grading! Good luck!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzCggYTtOLHA"
   },
   "source": [
    "## Part 1: Text Extraction AI\n",
    "\n",
    "For the Challenge in this chapter, we are going to build an AI agent that can (1) extract information from unstructured\n",
    "text, (2) run validation checks on the extracted data based on schema constraints and business logic rules, and (3) generate a structured response ready\n",
    "for downstream tools to process.\n",
    "\n",
    "This has many practical applications. You can imagine an assistant chatbot that extract information from loose text such as news,\n",
    "press releases, or even user's conversational queries, and then generate structured responses to be fed into a downstream tool. One might\n",
    "also imagine a chatbot that allow user to upload a document, extract information, and then perform some actions based on the extracted data.\n",
    "\n",
    "### 5 Instructions\n",
    "There are 5 instructions in total. Each successful implementation earns you 1 point. Successfully running the following cell (`python -m pytest`) with the expectected output earns you another 1 point.\n",
    "\n",
    "The total score for Part 1 is 6 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WOjbPKiBfU6",
    "outputId": "401039d7-9b5d-442e-f86a-9f81a7895e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\anaconda3\\envs\\training\\lib\\site-packages (0.3.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.23.4)\n",
      "Requirement already satisfied: anyio in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n",
      "Requirement already satisfied: langchain-openai in c:\\anaconda3\\envs\\training\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-openai) (0.3.15)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.52.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-openai) (1.53.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\envs\\training\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (4.66.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\envs\\training\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.52.0->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: langgraph in c:\\anaconda3\\envs\\training\\lib\\site-packages (0.2.44)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langgraph) (0.3.15)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langgraph) (2.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langgraph) (0.1.35)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse>=0.4.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.4.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.11)\n",
      "Requirement already satisfied: anyio in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
      "Requirement already satisfied: langchain-groq in c:\\anaconda3\\envs\\training\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-groq) (0.11.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-groq) (0.3.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\envs\\training\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (9.0.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\training\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-core\n",
    "!pip install langchain-openai\n",
    "!pip install langgraph\n",
    "!pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7LpQdAG6beJ",
    "outputId": "c117517b-ce94-46dc-b9d8-225bad5c3b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_parser.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_parser.py\n",
    "\n",
    "from typing import Optional\n",
    "import pytest\n",
    "import os\n",
    "import unittest\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, field_validator, model_validator\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROK_API_KEY\")\n",
    "\n",
    "# 1. bring in your llm\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    model_name=\"llama3-groq-70b-8192-tool-use-preview\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "class Stock(BaseModel):\n",
    "    \"\"\"Information about a company's stock\"\"\"\n",
    "\n",
    "    symbol: str = Field(description=\"The stock symbol\")\n",
    "    name: str = Field(description=\"The name of the company for which the stock symbol represents\")\n",
    "    sector: Optional[str] = Field(default=None, description=\"The sector of the company\")\n",
    "    industry: Optional[str] = Field(default=None, description=\"The industry of the company\")\n",
    "    market_cap: Optional[int] = Field(default=None, description=\"The market capitalization of the company\")\n",
    "    # 2. implement the other fields\n",
    "    # ...\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_symbol_4_letters(cls, values: dict) -> dict:\n",
    "        print(values)\n",
    "        symbol = values['symbol']\n",
    "        # 3. implement LLM validation logic\n",
    "        # ...\n",
    "        \n",
    "        if len(symbol) != 4:\n",
    "            raise ValueError(\"Symbol must be 4 letters long\")\n",
    "        return values\n",
    "    \n",
    "    @field_validator(\"market_cap\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_market_cap(cls, value: int) -> int:\n",
    "        print(value)\n",
    "        if value < 0:\n",
    "            raise ValueError(\"Market cap must be greater than 0\")\n",
    "        return value\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Stock)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "runnable = prompt | llm | parser\n",
    "\n",
    "\n",
    "class TestParser(unittest.TestCase):\n",
    "    def test_output_parser_symbol_valid(self):\n",
    "        text = \"\"\"\n",
    "        Bank Central Asia (BBCA) is a bank in Indonesia and is part of the finance sector.\n",
    "            It is in the banking industry and has a market capitalization of $8.5 billion.\n",
    "        \"\"\"\n",
    "        # 4. implement when symbol and market cap (and other fields) are all valid\n",
    "        out = runnable.invoke(text)\n",
    "        assert len(out.symbol) == 4\n",
    "        assert out.market_cap > 0\n",
    "        assert len(out.name) > 0\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def test_output_parser_symbol_invalid(self):\n",
    "        text = \"\"\"\n",
    "        Bank Central Asia (BCA) is a bank in Indonesia and is part of the finance sector.\n",
    "            It is in the banking industry and has a market capitalization of $8.5 billion.\n",
    "        \"\"\"\n",
    "\n",
    "        # assert exception is raised when the symbol is not 4 letters long\n",
    "        with pytest.raises(OutputParserException):\n",
    "            out = runnable.invoke(text)\n",
    "\n",
    "    def test_output_parser_mcap_invalid(self):\n",
    "        text = \"\"\"\n",
    "        Bank Central Asia (BBCA) is a bank in Indonesia and is part of the finance sector.\n",
    "            It is in the banking industry and has a market capitalization of $-8.5 billion.\n",
    "        \"\"\"\n",
    "\n",
    "        # 5. assert exception is raised when extraction task fail by detecting <0 market cap\n",
    "        with pytest.raises(OutputParserException):\n",
    "            out = runnable.invoke(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OkGEO2mBynI",
    "outputId": "f892bbd1-3760-4e2a-9ff8-3a05fefcf9b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.12.7, pytest-8.3.3, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\Arseno Feri Alzahabi\\OneDrive\\Project\\Sector Training\\LLM\\Challange\n",
      "plugins: anyio-4.6.2.post1\n",
      "collected 3 items\n",
      "\n",
      "test_parser.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 5.42s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 6. run this with 3 passes\n",
    "!python -m pytest test_parser.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-OdgLRmNHf6"
   },
   "source": [
    "- Do not alter any of the `text` prompt. Doing so invalidatest the purpose of the quiz / challenge.\n",
    "- Each correct implementation gets you 1 point. Successfully executing the cell above (`python -m pytest test_parser.py`) with the expected output gets you another 1 point. You get a total of 5+1 points from this section above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF20ZU6qQZBB"
   },
   "source": [
    "## Part 2: A LangGraph ReAct Agent with retriever tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8O6pqWWdQXKp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 7 companies based on P/E values, along with their full company name, company code, and PE values:\n",
      "1. ABM Investama Tbk - ABMM.JK - PE: 2.09\n",
      "2. Adaro Energy Indonesia Tbk - ADRO.JK - PE: 2.89\n",
      "3. Indo Tambangraya Megah Tbk - ITMG.JK - PE: 3.74\n",
      "4. United Tractors Tbk - UNTR.JK - PE: 3.99\n",
      "5. Baramulti Suksessarana Tbk - BSSR.JK - PE: 4.02\n",
      "6. Indika Energy Tbk - INDY.JK - PE: 4.03\n",
      "7. Golden Energy Mines Tbk - GEMS.JK - PE: 4.25\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.agents import AgentExecutor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "SECTORS_API_KEY = os.getenv('SECTOR_API_KEY')\n",
    "GROQ_API_KEY = os.getenv('GROK_API_KEY')\n",
    "\n",
    "\n",
    "def retrieve_from_endpoint(url: str) -> dict:\n",
    "    headers = {\"Authorization\": SECTORS_API_KEY}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        raise SystemExit(err)\n",
    "    return json.dumps(data)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_company_overview(stock: str) -> str:\n",
    "    \"\"\"\n",
    "    Get company overview\n",
    "\n",
    "    @param stock: The stock symbol of the company\n",
    "    @return: The company overview\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.sectors.app/v1/company/report/{stock}/?sections=overview\"\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "@tool\n",
    "def get_top_companies_ranked(dimension: str, n:str,year:str) -> List[str]:\n",
    "   # 7. implement this tool correctly, using the tool implementation above as reference\n",
    "\n",
    "   \"\"\"\n",
    "    Get top companies ranked by a certain dimension\n",
    "\n",
    "    @param dimension: The dimension to rank the companies by dividend_yield, Earnings, market_cap, pb, pe (P/E or price earning ratio), ps, revenue, total_dividend. This is a required field and only can fill by these list: ['dividend_yield', 'Earnings', 'market_cap', 'pb', 'pe', 'ps', 'revenue', 'total_dividend']\n",
    "    @param n: The number of companies to return. this is required field and only can fill by string number\n",
    "    @param year: year of the data if user don't fill this field, the default value is 2023\n",
    "    @sub_sector : sub sector of the company if user don't fill this field then don't give value because this is optional field\n",
    "    @return : The top companies ranked by the dimension\n",
    "   \"\"\"\n",
    "\n",
    "   url = f\"https://api.sectors.app/v1/companies/top/?classifications={dimension}&n_stock={n}&year={year}&sub_sector=&min_mcap_billion=5000\"\n",
    "   return retrieve_from_endpoint(url)\n",
    "\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    model_name=\"llama3-groq-70b-8192-tool-use-preview\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    get_company_overview,\n",
    "    get_top_companies_ranked,\n",
    "]\n",
    "\n",
    "# 8: ask that floating numbers are returned in 2 decimal points so the result is prettier\n",
    "# return full company name, symbol, and the value (in the case of companies by p/e values, return the p/e\n",
    "# but in 2 decimal points)\n",
    "\n",
    "system_message = \"Please provide the full company name, its symbol, and any associated values (such as P/E ratios) with floating-point numbers rounded to two decimal places for a cleaner presentation. If presenting companies by P/E values, ensure these values are rounded to two decimal points.Then sort the list from biggest value to smallest value.\"\n",
    "\n",
    "# 9: implement the below correctly, with llm, tools, and system_message as state modifier\n",
    "app = create_react_agent(llm, tools, state_modifier=system_message)\n",
    "\n",
    "def query_app(text: str) -> str:\n",
    "    out = app.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(text),\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    # return out[\"messages\"][-1].content\n",
    "    return out[\"messages\"]\n",
    "\n",
    "out_agent = query_app(\n",
    "    \"Get me the top 7 companies based on P/E values, along with their full company namem,company code, and PE values\"\n",
    ")\n",
    "\n",
    "print(out_agent[-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FQCjhNK8lpEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company overview for United Tractors Tbk (UNTR.JK) is as follows:\n",
      "\n",
      "- **Address:** Jl. Raya Bekasi km. 22, Cakung, Jakarta 13910\n",
      "- **Daily Close Change:** -0.0128\n",
      "- **Email:** ir@unitedtractors.com\n",
      "- **Employee Number:** 38,196\n",
      "- **Industry:** Machinery\n",
      "- **Last Close Price:** 27,000\n",
      "- **Latest Close Date:** 2024-11-05\n",
      "- **Listing Board:** Main\n",
      "- **Listing Date:** 1989-09-19\n",
      "- **Market Cap:** 98,058,868,097,024\n",
      "- **Market Cap Rank:** 19\n",
      "- **Phone:** 4605959; 4605979\n",
      "- **Sector:** Industrials\n",
      "- **Sub-Industry:** Construction Machinery & Heavy Vehicles\n",
      "- **Sub-Sector:** Industrial Goods\n",
      "- **Website:** www.unitedtractors.com\n"
     ]
    }
   ],
   "source": [
    "# 10: follow up now with a second question, to get the overview of whichever symbol\n",
    "# is 4th on the list above in `out_agent`\n",
    "\n",
    "out_agent2 = query_app(f\"{out_agent[-1].content}. get overview 4th company\")\n",
    "\n",
    "print(out_agent2[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwzLbPLfl-G2"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations on making your way through the challenges. My hope is that you find the session educational and fun, and I have, in my own way, inspired you to dive deeper into the exciting world of building financial chat agents using information retriever tools!\n",
    "\n",
    "Please submit a link to your Google Colab notebook at [the correct GitHub repository discussion thread](https://github.com/onlyphantom/llm-python/discussions/39) for grading. If you score higher than 8 points (out of a possible 10) you will obtain a certification jointly issued by Supertype and Sectors. Run all cells and show all output.\n",
    "\n",
    "If you need help, please reach out to us on Discord (exclusively for Practicum members).\n",
    "\n",
    "Thank you again for your participation, and I hope you walked away with lots of new ideas on what to build next!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
